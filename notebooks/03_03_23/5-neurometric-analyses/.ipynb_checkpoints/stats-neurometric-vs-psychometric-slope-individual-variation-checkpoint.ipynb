{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on \n",
    "- http://localhost:8187/notebooks/tsainbur/Projects/github_repos/cdcp_chronic/notebooks/neural-analysis/spiketrain_analyses/statements/3.1-categorical-unit-neurometric-relates-to-psychometric.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T23:22:54.330474Z",
     "start_time": "2022-02-20T23:22:54.298469Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T23:22:54.545451Z",
     "start_time": "2022-02-20T23:22:54.516266Z"
    }
   },
   "outputs": [],
   "source": [
    "save_figs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T23:22:54.758585Z",
     "start_time": "2022-02-20T23:22:54.728521Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# set to be lower priority\n",
    "#os.nice(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T23:22:54.995813Z",
     "start_time": "2022-02-20T23:22:54.966408Z"
    }
   },
   "outputs": [],
   "source": [
    "interpolations = [\n",
    "        \"AE\",\n",
    "        \"AF\",\n",
    "        \"AG\",\n",
    "        \"AH\",\n",
    "        \"BE\",\n",
    "        \"BF\",\n",
    "        \"BG\",\n",
    "        \"BH\",\n",
    "        \"CE\",\n",
    "        \"CF\",\n",
    "        \"CG\",\n",
    "        \"CH\",\n",
    "        \"DE\",\n",
    "        \"DF\",\n",
    "        \"DG\",\n",
    "        \"DH\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:41.886969Z",
     "start_time": "2022-01-25T01:15:40.526294Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "from cdcp.paths import DATA_DIR, ensure_dir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pathlib2 import Path\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:41.993503Z",
     "start_time": "2022-01-25T01:15:41.970784Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:42.019313Z",
     "start_time": "2022-01-25T01:15:41.996986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-23_23-02-31_846685'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"2021-10-07_16-05-58_796914\" '2021-10-06_13-30-08_899062' '2021-10-01_17-02-56_744915' \n",
    "statistics_timestamp = '2021-10-23_23-02-31_846685'# datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S_%f\")#\n",
    "statistics_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:42.117995Z",
     "start_time": "2022-01-25T01:15:42.021960Z"
    }
   },
   "outputs": [],
   "source": [
    "birds = [\n",
    "    ('B1597', '2021-05-14_12-40-20_423998', 'kilosort2_5'),\n",
    "    ('B1188', '2021-05-31_18-52-29_558216', 'kilosort2_5'),\n",
    "    ('B1595', '2021-07-10_16-42-47_090257', 'kilosort2'),\n",
    "    ('B1276', '2021-07-14_11-14-02_257025', 'kilosort2'),\n",
    "    ('B1426', '2021-07-14_11-29-39_657273', 'kilosort2'),\n",
    "    ('B1432', '2021-06-01_15-14-38_561892', 'kilosort2_5'),\n",
    "    ('B1170', '2021-06-01_21-01-26_519005', 'kilosort2_5'),\n",
    "    ('B1244', '2021-07-14_12-57-45_546674', 'kilosort2'),\n",
    "    ('B1593', '2021-06-28_18-13-24_826008', 'kilosort2_5'),\n",
    "    ('B1248', '2021-07-03_18-08-01_063431', 'kilosort2_5'),\n",
    "    # acute\n",
    "    #('B1279', '2021-04-12_16-27-07_289527', 'kilosort2_5'),\n",
    "    #('B1500', '2021-08-27_09-24-48_680961', 'kilosort2_5'),\n",
    "    #('B1239', '2021-05-17_22-18-51_557635', 'kilosort2'),\n",
    "    #('B1459', '2021-08-26_21-21-12_755614', 'kilosort2_5'),\n",
    "]\n",
    "birds_df = pd.DataFrame(birds, columns = ['bird', 'timestamp', 'sorter']).set_index('bird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:42.142354Z",
     "start_time": "2022-01-25T01:15:42.120132Z"
    }
   },
   "outputs": [],
   "source": [
    "identifiers = ['nm_by_interpolation_16_25', 'spike_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:50.439798Z",
     "start_time": "2022-01-25T01:15:42.162324Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "birds:  10%|█         | 1/10 [00:02<00:18,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1597 nrows per [6750, 6750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "birds:  20%|██        | 2/10 [00:02<00:07,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1188 nrows per [510, 510]\n",
      "B1595 nrows per [242, 242]\n",
      "B1276 nrows per [46, 46]\n",
      "B1426 nrows per [93, 93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "birds:  60%|██████    | 6/10 [00:02<00:01,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1432 nrows per [2157, 2157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "birds:  70%|███████   | 7/10 [00:03<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1170 nrows per [1281, 1281]\n",
      "B1244 nrows per [141, 141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "birds:  90%|█████████ | 9/10 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1593 nrows per [7714, 7714]\n"
     ]
    }
   ],
   "source": [
    "all_unit_statistics_df= []\n",
    "for bird, timestamp, sorter in tqdm(birds, desc='birds'):\n",
    "    \n",
    "    unit_statistics_df_list = []\n",
    "    for identifier in identifiers:\n",
    "        unit_statistics_df = pd.read_pickle(\n",
    "        DATA_DIR\n",
    "        / \"unit_statistics\"\n",
    "        / statistics_timestamp\n",
    "        / identifier\n",
    "        / \"{}.pickle\".format(bird)\n",
    "    )\n",
    "        unit_statistics_df_list.append(unit_statistics_df)\n",
    "        \n",
    "    print(bird, 'nrows per', [len(i) for i in unit_statistics_df_list])\n",
    "    \n",
    "    # combine dfs\n",
    "    unit_statistics_df = reduce(lambda x, y: pd.merge(x, y, on = 'unit', how='outer'), unit_statistics_df_list)\n",
    "    unit_statistics_df['bird'] = bird\n",
    "    \n",
    "    all_unit_statistics_df.append(unit_statistics_df)\n",
    "unit_statistics_df = pd.concat(all_unit_statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:50.840799Z",
     "start_time": "2022-01-25T01:15:50.441773Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge with categorical units\n",
    "categorical_units_df = pd.read_pickle(DATA_DIR / 'categorical_unit_01_23_22.pickle')\n",
    "categorical_units_df= categorical_units_df[categorical_units_df.categorical_unit == True]\n",
    "unit_statistics_df_cat = pd.merge(unit_statistics_df, categorical_units_df, on = ['bird', 'unit'])\n",
    "# subset categorical units\n",
    "#unit_statistics_df_cat = unit_statistics_df_cat[unit_statistics_df_cat.categorical_unit == True]\n",
    "unit_statistics_df = unit_statistics_df_cat\n",
    "print(len(unit_statistics_df))\n",
    "\n",
    "### merge with unit types\n",
    "unit_type_df = pd.read_pickle(DATA_DIR / \"unit_classes_01_23_22.pickle\")\n",
    "#unit_type_df = unit_type_df[[\"nuclei\",\"AP\",\"ML\",\"DV\",\"amplitude\",\"template_amplitude\",\"sr\",\"fw\",\"hw\",\"bird\",\"unit\"]]\n",
    "unit_statistics_df_ut = pd.merge(unit_statistics_df, unit_type_df, on = ['bird', 'unit'])\n",
    "unit_statistics_df = unit_statistics_df_ut\n",
    "print(len(unit_statistics_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_statistics_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt matrix into 1 row per interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:50.863922Z",
     "start_time": "2022-01-25T01:15:50.842598Z"
    }
   },
   "outputs": [],
   "source": [
    "interped_columns = [i  for i in unit_statistics_df.columns if i.split('_')[-1]  in interpolations]\n",
    "interped_columns_unique = np.unique(['_'.join(i.split('_')[:-1]) for i in interped_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:52.123286Z",
     "start_time": "2022-01-25T01:15:50.865512Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_dfs = []\n",
    "for col in tqdm(interped_columns_unique):\n",
    "    columns_to_subset = [\n",
    "        \"{}_{}\".format(col, i)\n",
    "        for i in interpolations\n",
    "        if \"{}_{}\".format(col, i) in unit_statistics_df.columns\n",
    "    ]\n",
    "    columns_to_subset += [\"bird\", \"unit\",\"bird_unit\", \"categoricality\"]\n",
    "    stat_df = unit_statistics_df[columns_to_subset].melt(id_vars=[\"bird\", \"unit\"])\n",
    "    stat_df.columns = [\"bird\", \"unit\", \"interp\", col]\n",
    "    stat_df[\"interp\"] = [i[-2:] for i in stat_df.interp.values]\n",
    "    stat_dfs.append(stat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:15:56.321817Z",
     "start_time": "2022-01-25T01:15:52.125009Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_df = reduce(lambda x, y: pd.merge(x, y, on = ['bird', 'unit', 'interp']), stat_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:16:09.549619Z",
     "start_time": "2022-01-25T01:15:56.323632Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_df = pd.merge(stat_df, unit_statistics_df_cat[\n",
    "    [\n",
    "        \"bird\",\n",
    "        \"unit\",\n",
    "        \"n_trials\",\n",
    "        \"n_cued_trials\",\n",
    "        \"n_incorrect_trials\",\n",
    "        \"n_correct_trials\",\n",
    "        \"n_reward_trials\",\n",
    "        \"n_passive_trials\",\n",
    "        \"n_active_trials\",\n",
    "        \"n_spikes\",\n",
    "        \"categorical_unit\",\n",
    "        \"categoricality\",\n",
    "        \n",
    "    ]\n",
    "], on = ['bird', 'unit'])\n",
    "\n",
    "for interped_column in tqdm(interped_columns_unique):\n",
    "    prop_nan = np.array(\n",
    "        [\n",
    "            np.mean(np.isnan(i)) if type(i) == np.ndarray else 1\n",
    "            for i in tqdm(stat_df[interped_column].values, leave=False, desc=interped_column)\n",
    "        ]\n",
    "    )\n",
    "    stat_df[\"{}_prop_nan\".format(interped_column)] = prop_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:16:09.763372Z",
     "start_time": "2022-01-25T01:16:09.551249Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:03.339371Z",
     "start_time": "2022-01-25T01:17:03.257022Z"
    }
   },
   "outputs": [],
   "source": [
    "slope_df = stat_df[[\n",
    "    'bird',\n",
    "    'unit',\n",
    "    'interp',\n",
    "    'nm_r2_cosine',\n",
    "    'nm_min_cosine',\n",
    "    'nm_max_cosine',\n",
    "    'nm_slope_cosine',\n",
    "    'nm_inflection_cosine',\n",
    "    'sm_cosine_prop_nan'\n",
    "    \n",
    "]].rename({\n",
    "    'nm_r2_cosine':'r2',\n",
    "    'sm_cosine_prop_nan':'sm_pct_nan',\n",
    "    'nm_slope_cosine':'slope',\n",
    "    'nm_max_cosine':'_max',\n",
    "    'nm_min_cosine':'_min',\n",
    "    'nm_inflection_cosine':'infleciton',\n",
    "}, axis='columns')\n",
    "slope_df['range'] = slope_df['_max']  - slope_df['_min'] \n",
    "slope_df['scaled_neurometric_slope'] = (slope_df['slope']  * slope_df['range'] ).astype(float)\n",
    "slope_df[\"log_scaled_neurometric_slope\"] = np.log( 1+\n",
    "    slope_df.scaled_neurometric_slope.values.astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:03.377333Z",
     "start_time": "2022-01-25T01:17:03.345149Z"
    }
   },
   "outputs": [],
   "source": [
    "slope_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:12.417818Z",
     "start_time": "2022-01-25T01:17:12.318520Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove bad fits\n",
    "print(len(slope_df))\n",
    "slope_df = slope_df[slope_df.sm_pct_nan < 0.01]\n",
    "print(len(slope_df))\n",
    "slope_df = slope_df[slope_df.slope.values.astype(float) < 99]\n",
    "print(len(slope_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df_interp = pd.read_pickle(DATA_DIR/'behavior'/'fit_df_interp.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.094213Z",
     "start_time": "2022-01-25T01:17:30.050406Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_df_interp[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.117151Z",
     "start_time": "2022-01-25T01:17:30.095740Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_df_interp[\"scaled_psychometric_slope\"] = (\n",
    "    fit_df_interp._slope * (fit_df_interp._max - fit_df_interp._min)\n",
    ").values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.139172Z",
     "start_time": "2022-01-25T01:17:30.118777Z"
    }
   },
   "outputs": [],
   "source": [
    "psychometric_slope_df = fit_df_interp[fit_df_interp.cue == 'NC'][['bird', 'interp', '_slope', 'scaled_psychometric_slope']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.163262Z",
     "start_time": "2022-01-25T01:17:30.140824Z"
    }
   },
   "outputs": [],
   "source": [
    "psychometric_slope_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.258634Z",
     "start_time": "2022-01-25T01:17:30.164659Z"
    }
   },
   "outputs": [],
   "source": [
    "neurometric_psychometric_slope_df = slope_df.merge(\n",
    "    psychometric_slope_df, on=[\"bird\", \"interp\"]\n",
    ")\n",
    "neurometric_psychometric_slope_df = neurometric_psychometric_slope_df.rename(\n",
    "    columns={\"_slope\": \"psychometric_slope\", \"slope\": \"neurometric_slope\"}\n",
    ")\n",
    "neurometric_psychometric_slope_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.281969Z",
     "start_time": "2022-01-25T01:17:30.260224Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "neurometric_psychometric_slope_df[\"log_scaled_psychometric_slope\"] = np.log(1+\n",
    "    neurometric_psychometric_slope_df.scaled_psychometric_slope\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:30.301243Z",
     "start_time": "2022-01-25T01:17:30.283610Z"
    }
   },
   "outputs": [],
   "source": [
    "len(neurometric_psychometric_slope_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot relationship between neurometric and psychometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:36.534959Z",
     "start_time": "2022-01-25T01:17:36.512438Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_descriptive_neurometric_psychometric(\n",
    "    bird_neurometric_psychometric,\n",
    "    neurometric_column=\"neurometric_slope\",\n",
    "    psychometric_column=\"psychometric_slope\",\n",
    "):\n",
    "    neurometric_description = (\n",
    "        bird_neurometric_psychometric[[\"interp\", neurometric_column]]\n",
    "        .groupby([\"interp\"])\n",
    "        .describe()[[neurometric_column]][neurometric_column][[\"count\", \"mean\", \"std\"]]\n",
    "    )\n",
    "    neurometric_description[\"sem\"] = neurometric_description[\"std\"] / np.sqrt(\n",
    "        neurometric_description[\"count\"]\n",
    "    )\n",
    "    neurometric_description = neurometric_description[[\"mean\", \"sem\"]]\n",
    "    neurometric_description.columns = [\"neurometric_mean\", \"neurometric_sem\"]\n",
    "\n",
    "    psychometric_description = (\n",
    "        bird_neurometric_psychometric[[\"interp\", psychometric_column]]\n",
    "        .groupby([\"interp\"])\n",
    "        .describe()[[psychometric_column]][psychometric_column][[\"mean\"]]\n",
    "    )\n",
    "    psychometric_description.columns = [\"psychometric_mean\"]\n",
    "    neurometric_psychometric_mean = pd.concat(\n",
    "        [psychometric_description, neurometric_description], axis=1\n",
    "    )\n",
    "    return neurometric_psychometric_mean\n",
    "\n",
    "def z_score(x):\n",
    "    return (x-np.mean(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:36.569482Z",
     "start_time": "2022-01-25T01:17:36.536528Z"
    }
   },
   "outputs": [],
   "source": [
    "neurometric_psychometric_slope_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Z score scaled neurometric and psychometric by bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T01:17:36.683652Z",
     "start_time": "2022-01-25T01:17:36.570982Z"
    }
   },
   "outputs": [],
   "source": [
    "neurometric_psychometric_slope_df_list = []\n",
    "for bird in neurometric_psychometric_slope_df.bird.unique():\n",
    "    bird_neurometric_psychometric = neurometric_psychometric_slope_df[\n",
    "        neurometric_psychometric_slope_df.bird == bird\n",
    "    ]\n",
    "    bird_neurometric_psychometric[\"z_score_log_scaled_neurometric_slope\"] = z_score(\n",
    "        bird_neurometric_psychometric[\"log_scaled_neurometric_slope\"]\n",
    "    )\n",
    "    bird_neurometric_psychometric[\"z_score_log_scaled_psychometric_slope\"] = z_score(\n",
    "        bird_neurometric_psychometric[\"log_scaled_psychometric_slope\"]\n",
    "    )\n",
    "    bird_neurometric_psychometric[\"z_score_scaled_neurometric_slope\"] = z_score(\n",
    "        bird_neurometric_psychometric[\"scaled_neurometric_slope\"]\n",
    "    )\n",
    "    bird_neurometric_psychometric[\"z_score_scaled_psychometric_slope\"] = z_score(\n",
    "        bird_neurometric_psychometric[\"scaled_psychometric_slope\"]\n",
    "    )\n",
    "    neurometric_psychometric_slope_df_list.append(bird_neurometric_psychometric)\n",
    "neurometric_psychometric_slope_df = pd.concat(neurometric_psychometric_slope_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurometric_psychometric_slope_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = neurometric_psychometric_slope_df[\n",
    "    [\n",
    "        \"bird\",\n",
    "        \"unit\",\n",
    "        \"interp\",\n",
    "        \"log_scaled_neurometric_slope\",\n",
    "        \"log_scaled_psychometric_slope\",\n",
    "    ]\n",
    "].sort_values(by=['unit', 'interp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bird_unit\"] = [\"\".join([row.bird, row.unit]) for idx, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear mixed-effects model\n",
    "model = smf.mixedlm(\"log_scaled_neurometric_slope ~ log_scaled_psychometric_slope + C(interp)\", \n",
    "                    data=df,\n",
    "                    groups=df[\"df\"],\n",
    "                    missing=\"drop\")\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesized_value = 0\n",
    "degf = result.df_resid\n",
    "coef = result.params[\"log_scaled_psychometric_slope\"]\n",
    "se = result.bse[\"log_scaled_psychometric_slope\"]\n",
    "degf, coef, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_value = (coef - hypothesized_value) / se\n",
    "t_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = t.sf(t_value, degf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdcp_paper",
   "language": "python",
   "name": "cdcp_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
